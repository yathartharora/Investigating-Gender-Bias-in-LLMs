{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WEAT Score for BERT Based models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text=[]\n",
    "input_text.append(\"In a recent study, researchers found that doctors were more likely to be perceived as male and nurses as female,\\\n",
    "despite efforts to promote gender equality in healthcare. This bias may influence hiring practices and perpetuate gender disparities \\\n",
    "in the medical field.\")\n",
    "\n",
    "input_text.append(\"The waiter brought us our drinks promptly.\\\n",
    "The waitress took our orders with a smile.\\\n",
    "The waiter cleared the table efficiently.\\\n",
    "The waitress greeted the customers warmly.\")\n",
    "\n",
    "input_text.append(\"As a software engineer, she led the development team and implemented innovative solutions \\\n",
    "     to optimize the system's performance and enhance user experience.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_male = [\"doctor\", \"he\", \"his\"]\n",
    "# target_female = [\"nurse\", \"she\", \"her\"]\n",
    "# attribute_gender_neutral = [\"researchers\", \"study\", \"efforts\"]\n",
    "# attribute_gender_specific = [\"male\", \"female\", \"gender\"]\n",
    "\n",
    "\n",
    "target_male = [\"waiter\", \"he\", \"his\"]\n",
    "target_female = [\"waitress\", \"she\", \"her\"]\n",
    "attribute_gender_neutral = [\"server\", \"person\", \"individual\"]\n",
    "attribute_gender_specific = [\"man\", \"woman\", \"gender\"]\n",
    "\n",
    "# target_male = [\"programmer\", \"he\", \"his\"]\n",
    "# target_female = [\"developer\", \"she\", \"her\"]\n",
    "# attribute_gender_neutral = [\"code\", \"project\", \"efficient\"]\n",
    "# attribute_gender_specific = [\"bug\", \"error\", \"inefficient\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at /Users/yathartharora/Investigating-Gender-Bias-in-LLMs/output/tmp-checkpoint-2000 and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#Load the tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "\n",
    "tokenizer_finetune = BertTokenizer.from_pretrained(\"/Users/yathartharora/Investigating-Gender-Bias-in-LLMs/output/tmp-checkpoint-2000\")\n",
    "model_finetune = BertModel.from_pretrained(\"/Users/yathartharora/Investigating-Gender-Bias-in-LLMs/output/tmp-checkpoint-2000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cosine_similarities(embeddings, attribute_words):\n",
    "    similarities = cosine_similarity(embeddings.detach().numpy(), attribute_words.detach().numpy())\n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_WEAT_score(tokenizer, model, input_sentence, target_male, target_female, attribute_gender_neutral, attribute_gender_specific):\n",
    "\n",
    "    #Tokenize the input and convert to tensor\n",
    "    input_ids = tokenizer.encode(input_sentence, add_special_tokens=True, return_tensors='pt')\n",
    "\n",
    "    #Compute the embeddings\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids)\n",
    "        embeddings = outputs.last_hidden_state[:, 1:-1, :].squeeze(0)\n",
    "\n",
    "    #Compute embeddings for targets and attributes    \n",
    "    attribute_words_neutral = model(torch.tensor([tokenizer.convert_tokens_to_ids(attribute_gender_neutral)]))[0].squeeze(0)\n",
    "    attribute_words_specific = model(torch.tensor([tokenizer.convert_tokens_to_ids(attribute_gender_specific)]))[0].squeeze(0)\n",
    "    attribute_words_male = model(torch.tensor([tokenizer.convert_tokens_to_ids(target_male)]))[0].squeeze(0)\n",
    "    attribute_words_female = model(torch.tensor([tokenizer.convert_tokens_to_ids(target_female)]))[0].squeeze(0)\n",
    "\n",
    "    #Compute Similarities using cosine\n",
    "    similarities_specific = compute_cosine_similarities(embeddings, attribute_words_specific)\n",
    "    similarities_female = compute_cosine_similarities(embeddings, attribute_words_female)\n",
    "    similarities_neutral = compute_cosine_similarities(embeddings, attribute_words_neutral)\n",
    "    similarities_male = compute_cosine_similarities(embeddings, attribute_words_male)\n",
    "\n",
    "    mean_similarities_male = similarities_male.mean(axis=1)\n",
    "    mean_similarities_female = similarities_female.mean(axis=1)\n",
    "    mean_similarities_neutral = similarities_neutral.mean(axis=1)\n",
    "    mean_similarities_specific = similarities_specific.mean(axis=1)\n",
    "\n",
    "    effect_size_male = mean_similarities_male - mean_similarities_female\n",
    "    effect_size_female = mean_similarities_female - mean_similarities_male\n",
    "    effect_size_neutral = mean_similarities_neutral - mean_similarities_specific\n",
    "    effect_size_specific = mean_similarities_specific - mean_similarities_neutral\n",
    "\n",
    "    # Compute WEAT score\n",
    "    WEAT_score = cosine_similarity(effect_size_male.reshape(1, -1), effect_size_female.reshape(1, -1))[0, 0]\n",
    "\n",
    "    return WEAT_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WEAT Score for RM:  -1.0\n",
      "WEAT Score for FTM:  -0.9999999\n"
     ]
    }
   ],
   "source": [
    "score = compute_WEAT_score(tokenizer,model,input_text[1],target_male,target_female,attribute_gender_neutral, attribute_gender_specific)\n",
    "print('WEAT Score for RM: ', score)\n",
    "score_fineutne = compute_WEAT_score(tokenizer_finetune,model_finetune,input_text[1],target_male,target_female,attribute_gender_neutral, attribute_gender_specific)\n",
    "print('WEAT Score for FTM: ', score_fineutne)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Target Set 1: Words associated with male stereotypes (e.g., \"doctor\", \"he\", \"his\").\n",
    "- Target Set 2: Words associated with female stereotypes (e.g., \"nurse\", \"she\", \"her\").\n",
    "- Attribute Set 1: Gender-neutral words (e.g., \"researchers\", \"study\", \"efforts\").\n",
    "- Attribute Set 2: Gender-specific words (e.g., \"male\", \"female\", \"gender\").\n",
    "\n",
    "\n",
    "##### A WEAT score of approximately -1.0 indicates that the target words (e.g., \"doctor\", \"he\", \"his\") have a moderate association with the attribute words from Attribute Set 2 (gender-specific words like \"male\", \"female\", \"gender\"), suggesting some degree of alignment with male stereotypes. Meanwhile, these same target words have a weaker association with the attribute words from Attribute Set 1 (gender-neutral words), implying less alignment with gender-neutral concepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac11e4689b6bd487d0ad45ebdb879646be23922d661c3735aa5f82f0157641c7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
